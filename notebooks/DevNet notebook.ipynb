{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from custom_plot_confusion import plot_confusion_matrix_\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, validation_curve\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from mlxtend.data import loadlocal_mnist\n",
    "\n",
    "EXP_COUNT = 1\n",
    "random_state = np.random.RandomState(42)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/mnt/data/All Datasets/App2_data/data/'\n",
    "MODEL_NAME = 'DevNet'\n",
    "N_PAK = 4\n",
    "MAL_PER = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    '''returns train and test dataframe from csv files'''\n",
    "    \n",
    "    def __init__(self, path, model_name, n_packets=4, mal_per=5):\n",
    "        self.path = path\n",
    "        self.mal_per = mal_per\n",
    "        self.n = n_packets\n",
    "        self.model_name = model_name\n",
    "        \n",
    "    def get_file(self,):\n",
    "        seek_arg = '*/*/*' + str(self.n) + '.csv' \n",
    "        files = glob(os.path.join(self.path, seek_arg))\n",
    "        tr_files = [f for f in files if f.split('/')[-2]=='train']\n",
    "        te_files = [f for f in files if f.split('/')[-2]=='test']\n",
    "        return tr_files, te_files        \n",
    "\n",
    "    def load_data(self,):\n",
    "        train_files, test_files = self.get_file()\n",
    "        df_train = self._read_csv(train_files, 'train')\n",
    "        df_test = self._read_csv(test_files, 'test')\n",
    "        return df_train, df_test\n",
    "    \n",
    "    def _read_csv(self, files, mode):\n",
    "        df = pd.DataFrame()\n",
    "        for file in tqdm(files):\n",
    "            traffic_class = file.split('/')[-3]\n",
    "            traffic_idx = (1 if traffic_class=='malware' else 0)\n",
    "            if (mode=='test' and traffic_class=='malware'):\n",
    "                traffic_class = traffic_class + str('_') + file.split('/')[-1].split('_')[0]\n",
    "            df_temp = pd.read_csv(file)\n",
    "            df_temp = df_temp.assign(traffic_class=traffic_class)\n",
    "            df_temp = df_temp.assign(traffic_idx=traffic_idx)\n",
    "            df = df.append(df_temp)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "            \n",
    "        if self.model_name=='DevNet' and mode=='train':\n",
    "            benign_size = df[df['traffic_class']!='malware'].shape[0]\n",
    "            malware_size = df[df['traffic_class']=='malware'].shape[0]\n",
    "            sample_size = int((benign_size*self.mal_per)/100)\n",
    "            drop_size = malware_size-sample_size\n",
    "            df = df.drop((df['traffic_class']=='malware').sample(drop_size).index)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processor = DataProcessor(path=DATA_DIR, model_name=MODEL_NAME, n_packets=N_PAK, mal_per=MAL_PER)\n",
    "df_train, df_test = data_processor.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "       'udps.src_port',\n",
    "       'udps.dst_port', 'udps.protocol', \n",
    "       'udps.src2dst_raw_size', \n",
    "       'udps.dst2src_raw_size', \n",
    "       'udps.src2dst_ip_size', \n",
    "       'udps.dst2src_ip_size', \n",
    "       'udps.src2dst_transport_size', \n",
    "       'udps.dst2src_transport_size', \n",
    "       'udps.src2dst_payload_size', \n",
    "       'udps.dst2src_payload_size', \n",
    "       'udps.src2dst_total_packet_size', \n",
    "       'udps.dst2src_total_packet_size', 'udps.src2dst_max_ps',\n",
    "       'udps.dst2src_max_ps', 'udps.src2dst_min_ps', 'udps.dst2src_min_ps',\n",
    "       'udps.src2dst_mean_ps', 'udps.dst2src_mean_ps', 'udps.src2dst_std_ps',\n",
    "       'udps.dst2src_std_ps', 'udps.src2dst_syn_count',\n",
    "       'udps.dst2src_syn_count', 'udps.src2dst_ece_count',\n",
    "       'udps.dst2src_ece_count', 'udps.src2dst_cwr_count',\n",
    "       'udps.dst2src_cwr_count', 'udps.src2dst_urg_count',\n",
    "       'udps.dst2src_urg_count', 'udps.src2dst_ack_count',\n",
    "       'udps.dst2src_ack_count', 'udps.src2dst_psh_count',\n",
    "       'udps.dst2src_psh_count', 'udps.src2dst_rst_count',\n",
    "       'udps.dst2src_rst_count', 'udps.src2dst_fin_count',\n",
    "       'udps.dst2src_fin_count',\n",
    "       'udps.src2dst_piat_mean_ms',\n",
    "       'udps.dst2src_piat_mean_ms', 'udps.src2dst_piat_min_ms',\n",
    "       'udps.dst2src_piat_min_ms', 'udps.src2dst_piat_max_ms',\n",
    "       'udps.dst2src_piat_max_ms', 'udps.src2dst_piat_std_ms',\n",
    "       'udps.dst2src_piat_std_ms'    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.loc[df_train[selected_features].dropna().index]\n",
    "df_test = df_test.loc[df_test[selected_features].dropna().index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = preprocessing.StandardScaler()\n",
    "\n",
    "df_train[selected_features] = encoder.fit_transform(df_train[selected_features].values)\n",
    "df_test[selected_features] = encoder.transform(df_test[selected_features].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features.append('traffic_idx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = pd.concat([df_test[(df_test['traffic_class']=='intrusion')].sample(n=5000),\n",
    "                      df_test[(df_test['traffic_class']=='benign')].sample(n=5000),\n",
    "                      df_test[(df_test['traffic_class']=='malware_old')].sample(n=10000)]).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4096\n",
    "\n",
    "train_loader = DataLoader(df_train[selected_features].values, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(df_valid[selected_features].values, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DevNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(DevNet, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(45, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deviation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class GaussianPriorScore:\n",
    "    def __init__(self, num_samples, mu=0.0, std=1.0):\n",
    "        self.num_samples = num_samples\n",
    "        self.mu = mu\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self):\n",
    "        samples = torch.normal(self.mu, self.std, (self.num_samples,))\n",
    "        std, mu = torch.std_mean(samples)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            std = std.cuda()\n",
    "            mu = mu.cuda()\n",
    "\n",
    "        return std, mu\n",
    "\n",
    "prior_score = GaussianPriorScore(5000)\n",
    "\n",
    "def deviation_loss(y_labels, y_preds, margin=5):\n",
    "    std, mu = prior_score()\n",
    "\n",
    "    y_preds = y_preds.view(-1)\n",
    "    y_labels = y_labels.view(-1)\n",
    "    \n",
    "    deviation = (y_preds - mu) / std\n",
    "\n",
    "    loss = (1 - y_labels) * torch.abs(deviation) + y_labels * F.relu(margin - deviation)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tail_end = '_n{}_{}%_expno_'.format(N_PAK, MAL_PER)\n",
    "exp_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S') + str('_') + tail_end \n",
    "filename = \"model/after_jun_7/DevNet_checkpoint_\" + exp_time + str(EXP_COUNT) + '.pth.tar'\n",
    "\n",
    "start_epoch = 0\n",
    "best_acc = 0\n",
    "lr_rate = 0.0001\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DevNet()\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "if cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "criterion = deviation_loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr_rate, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model, input_size=(45,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, train_loader):\n",
    "    model.train()\n",
    "    avg_loss = 0\n",
    "    for idx, packed_data in enumerate(train_loader):\n",
    "        input_data, targets = Variable(packed_data[:, :-1], volatile=True), Variable(packed_data[:, -1])\n",
    "        if cuda:\n",
    "            input_data, true_labels = input_data.float().cuda(), targets.float().cuda()\n",
    "        pred_labels = model(input_data)\n",
    "        loss = criterion(true_labels, pred_labels).mean()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_val = loss.detach().cpu().item()\n",
    "        \n",
    "        print(f\"\\rIteration: {idx}/{len(train_loader)} \\t Loss = {loss_val}\", end='')\n",
    "        avg_loss = (avg_loss * idx + loss_val) / (idx + 1)\n",
    "\n",
    "    print('\\n\\rEpoch {}/{}, loss:{:0.4f}\\n'.format(epoch+1, num_epochs, avg_loss))\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, optimizer, criterion, valid_loader):\n",
    "    model.eval()\n",
    "    valid_loss = []\n",
    "    valid_preds = []\n",
    "    valid_target = []\n",
    "    for i, packed_data in enumerate(valid_loader):\n",
    "        input_data, targets = Variable(packed_data[:, :-1], volatile=True), Variable(packed_data[:, -1])\n",
    "        if cuda:\n",
    "            input_data, targets = input_data.float().cuda(), targets.float().cuda()\n",
    "        output = model(input_data)\n",
    "        loss = criterion(targets, output)\n",
    "        valid_loss.append(loss.detach().cpu().numpy())\n",
    "        valid_preds.append(output.detach().cpu().numpy())\n",
    "        valid_target.append(targets.cpu().numpy())\n",
    "        \n",
    "    total_loss = np.concatenate(valid_loss)\n",
    "    total_preds = np.concatenate(valid_preds)\n",
    "    total_target = np.concatenate(valid_target)\n",
    "        \n",
    "    accuracy = metrics.accuracy_score(total_target, (total_preds > 0.5))\n",
    "    \n",
    "    avg_ib_loss = float(np.mean(total_loss[:5000]))\n",
    "    avg_pb_loss = float(np.mean(total_loss[5000:10000]))\n",
    "    avg_pm_loss = float(np.mean(total_loss[10000:]))\n",
    "    \n",
    "    return accuracy, avg_ib_loss, avg_pb_loss, avg_pm_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "valid_ib_loss = []\n",
    "valid_pb_loss = []\n",
    "valid_pm_loss = []\n",
    "for epoch in range(num_epochs): \n",
    "    train_l = train(model=model, optimizer=optimizer, criterion=criterion, train_loader=train_loader)\n",
    "    train_loss.append(train_l)    \n",
    "    accuracy, ib_l, pb_l, pm_l = validate(model=model,\n",
    "                                           optimizer=optimizer, \n",
    "                                           criterion=criterion,\n",
    "                                           valid_loader=valid_loader\n",
    "                                          )\n",
    "    valid_ib_loss.append(ib_l)\n",
    "    valid_pb_loss.append(pb_l)\n",
    "    valid_pm_loss.append(pm_l)\n",
    "    if accuracy > best_acc:\n",
    "        state = {'epoch': start_epoch + epoch + 1,\n",
    "             'state_dict': model.state_dict(),\n",
    "             'best_accuracy': accuracy}\n",
    "        best_acc = max(accuracy, best_acc)\n",
    "        print('[INFO] Best model found with acc: {:0.4}\\n'.format(accuracy))\n",
    "        torch.save(state, filename)\n",
    "    else:\n",
    "        print('Model not improved\\n')\n",
    "EXP_COUNT += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_categories = ['train_loss', 'valid_ib_loss', 'valid_pb_loss', 'valid_pm_loss'] \n",
    "\n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.plot(np.array(train_loss), lw=2)\n",
    "plt.plot(np.array(valid_ib_loss), lw=2)\n",
    "plt.plot(np.array(valid_pb_loss), lw=2)\n",
    "plt.plot(np.array(valid_pm_loss), lw=2)\n",
    "plt.title('Loss curves', fontsize=25)\n",
    "plt.xlabel('Epochs', fontsize=20)\n",
    "plt.ylabel('Deviation Loss', fontsize=20)\n",
    "plt.legend(valid_categories, fontsize=16, loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(filename):\n",
    "    print('[INFO] Loading checkpoint...', filename)\n",
    "    if cuda:\n",
    "        checkpoint = torch.load(filename)\n",
    "    else:\n",
    "        checkpoint = torch.load(filename, \n",
    "                               map_location=lambda storage,loc:storage)\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    best_accuracy = checkpoint['best_accuracy']\n",
    "    model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate anomaly score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_score(df_test, selected_features, batch_size, model, criterion):\n",
    "    model.eval()\n",
    "    y = np.array([])\n",
    "    data_arr = df_test[selected_features].values\n",
    "    test_loader = DataLoader(data_arr, batch_size=batch_size)\n",
    "    for idx, packed_data in enumerate(test_loader):\n",
    "        input_data, targets = Variable(packed_data[:, :-1], volatile=True), Variable(packed_data[:, -1])\n",
    "        if cuda:\n",
    "            input_data, true_labels = input_data.float().cuda(), targets.float().cuda()\n",
    "        pred_labels = model(input_data)\n",
    "        y = np.concatenate([y, pred_labels.detach().cpu().numpy()[:, 0]])\n",
    "    df_test = df_test.assign(y=y)\n",
    "    return df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(bscore, mscore, detection_thresh, title):\n",
    "    ytrue = np.array([0]*len(bscore) + [1]*len(mscore))\n",
    "    ypred = np.concatenate([bscore, mscore])\n",
    "        \n",
    "    ypred = (ypred > detection_thresh).astype(int)\n",
    "    cm = metrics.confusion_matrix(ytrue, ypred, labels=[0, 1])\n",
    "    \n",
    "    plot_confusion_matrix_(cm, ['Benign', 'Malware'], title=title, \n",
    "                           detection_thresh=detection_thresh, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_score = predict_score(df_test, selected_features, batch_size, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta_labels = df_test_score[df_test_score['traffic_class']=='malware_mta']['sublabel'].unique()\n",
    "labels_2021 = [l for l in mta_labels if l.startswith('2021')]\n",
    "ransom_labels = [label for label in mta_labels if 'ransomware' in list(map(lambda x: x.lower(), label.split('-')))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating classwise malware score\n",
    "mta2021_score = df_test_score.loc[df_test_score['sublabel'].isin(labels_2021)]['y'].values\n",
    "ransom_score = df_test_score.loc[df_test_score['sublabel'].isin(ransom_labels)]['y'].values\n",
    "\n",
    "pm_score = df_test_score[df_test_score['traffic_class']=='malware_old']['y'].values\n",
    "ddos_score = df_test_score[df_test_score['label']=='ddos2019']['y'].values\n",
    "doh_score = df_test_score[(df_test_score['label']=='DoH__iodine') |\n",
    "                        (df_test_score['label']=='DoH__dnscat2')]['y'].values\n",
    "botnet_score = df_test_score[df_test_score['label']=='ISCX_Botnet']['y'].values\n",
    "pb_score = df_test_score[df_test_score['traffic_class']=='benign']['y'].values\n",
    "ib_score = df_test_score[df_test_score['traffic_class']=='intrusion']['y'].values\n",
    "\n",
    "total_score = np.concatenate([\n",
    "    pm_score,\n",
    "    ransom_score,\n",
    "    mta2021_score,\n",
    "    ddos_score,\n",
    "    doh_score,\n",
    "    botnet_score,\n",
    "    pb_score,\n",
    "    ib_score    \n",
    "])\n",
    "\n",
    "total_labels = np.array(\n",
    "    ['Public Malware']*pm_score.shape[0] +\n",
    "    ['MTA Ransomware Malware']*ransom_score.shape[0] +\n",
    "    ['2021 Malware']*mta2021_score.shape[0] +\n",
    "    ['DDoS Malware']*ddos_score.shape[0] +\n",
    "    ['DoH Malware']*doh_score.shape[0] +\n",
    "    ['ISCX Botnet Malware']*botnet_score.shape[0] +\n",
    "    ['Public Benign']*pb_score.shape[0] +\n",
    "    ['Intrusion Benign']*ib_score.shape[0])\n",
    "\n",
    "df_score = pd.DataFrame({'category': total_labels,\n",
    "                        'score': total_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "dataset_types = ['Public Malware',\n",
    "                'MTA Ransomware Malware',\n",
    "                '2021 Malware',\n",
    "                'DDoS Malware',\n",
    "                'DoH Malware',\n",
    "                'ISCX Botnet Malware',\n",
    "                'Public Benign',\n",
    "                'Intrusion Benign']\n",
    "\n",
    "matplotlib.rc(\"font\", size=18)\n",
    "colors = plt.rcParams[\"axes.prop_cycle\"]()\n",
    "\n",
    "fig, axes = plt.subplots(len(dataset_types), figsize=(15, 30))\n",
    "fig.tight_layout()\n",
    "\n",
    "for idx, malware_type in enumerate(dataset_types):\n",
    "    c = next(colors)[\"color\"]\n",
    "    anomaly_score = df_score[df_score['category']==malware_type]['score']  \n",
    "    axes[idx].hist(anomaly_score, bins=100, color=c)\n",
    "    axes[idx].grid(axis='y', alpha=0.75)\n",
    "    axes[idx].set_title(malware_type)\n",
    "    axes[idx].set_ylabel('Session counts')\n",
    "    \n",
    "plt.title(\"Histogram Plot - Anomaly score for DevNet\")\n",
    "plt.xlabel(\"Anomaly-Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malware_categories = ['Public Malware',\n",
    "                'MTA Ransomware Malware',\n",
    "                '2021 Malware',\n",
    "                'DDoS Malware',\n",
    "                'DoH Malware',\n",
    "                'ISCX Botnet Malware']\n",
    "\n",
    "detection_thresh = [2.5, 2, 1.5, 1, 0.5, 0.1, 0.05]\n",
    "\n",
    "for category in malware_categories:\n",
    "    benign_score = df_score[df_score['category']=='Intrusion Benign']['score'].values\n",
    "    malware_score = df_score[df_score['category']==category]['score'].values\n",
    "    print('For', category)\n",
    "    for thresh in detection_thresh:\n",
    "        get_metrics(np.random.choice(benign_score, len(malware_score)), \n",
    "                    malware_score, detection_thresh=thresh, title=category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
